{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 09:46:40.723928: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-25 09:46:42.084194: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-25 09:46:42.087282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 09:46:45.683655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous work - Load, Transform data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('./usercode/train.csv')\n",
    "train_data = df_train['text'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am still waiting on my card?'\n",
      " \"What can I do if my card still hasn't arrived after 2 weeks?\"\n",
      " 'I have been waiting over a week. Is the card still coming?' ...\n",
      " 'What countries are getting support?' 'Are cards available in the EU?'\n",
      " 'Which countries are represented?'] \n",
      "\n",
      " [[2, 49, 63, 209, 29, 3, 7], [14, 11, 2, 9, 55, 3, 7, 63, 122, 276, 163, 457, 306]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenize the numpy array of texts.\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(train_data)\n",
    "\n",
    "# 1.1 We convert the texts to sequence after learning from training data\n",
    "train_seq = tokenizer.texts_to_sequences(train_data)\n",
    "print(train_data, '\\n\\n' ,train_seq[:2])\n",
    "\n",
    "# Next, we tokenize the textual comments using the Tokenizer provided by Keras.\n",
    "#  We use the training set comments alone to build a vocabulary of tokens, \n",
    "# and use them to convert all the comments into a (padded) sequence of tokens of the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 711  632   71    0    0    0]\n",
      " [  73    8 3215   55  927    0]\n",
      " [  83   91    1  645 1253  927]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Understanding padding and masking\n",
    "# Masking is a way to tell sequence-processing layers that certain timesteps\n",
    "# in an input are missing, and thus should be skipped when processing the data.\n",
    "\n",
    "# Padding comes from the need to encode sequence data into contiguous batches: \n",
    "# in order to make all sequences in a batch fit a given standard length, \n",
    "# it is necessary to pad or truncate some sequences.\n",
    "\n",
    "'''\n",
    "[\n",
    "  [\"Hello\", \"world\", \"!\"],\n",
    "  [\"How\", \"are\", \"you\", \"doing\", \"today\"],\n",
    "  [\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\"],\n",
    "]\n",
    "\n",
    "[\n",
    "  [71, 1331, 4231]\n",
    "  [73, 8, 3215, 55, 927],\n",
    "  [83, 91, 1, 645, 1253, 927],\n",
    "]\n",
    "\n",
    "# The data is a nested list where individual samples have length 3, 5, and 6, respectively.\n",
    "# Since the input data for a deep learning model must be a single tensor\n",
    "# (of shape e.g. (batch_size, 6, vocab_size) in this case), \n",
    "# samples that are shorter than the longest item need to be padded\n",
    "#  with some placeholder value\n",
    "'''\n",
    "\n",
    "\n",
    "raw_inputs = [\n",
    "    [711, 632, 71],\n",
    "    [73, 8, 3215, 55, 927],\n",
    "    [83, 91, 1, 645, 1253, 927],\n",
    "]\n",
    "\n",
    "# By default, this will pad using 0s; it is configurable via the \"value\" parameter.\n",
    "# Note that you could use \"pre\" padding (at the beginning) or \"post\" padding (at the end).\n",
    "# We recommend using \"post\" padding when working with RNN layers\n",
    "# (in order to be able to use the CuDNN implementation of the layers).\n",
    "padded_inputs = tf.keras.utils.pad_sequences(raw_inputs, padding=\"post\")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 49, 63, 209, 29, 3, 7], [14, 11, 2, 9, 55, 3, 7, 63, 122, 276, 163, 457, 306]] \n",
      "\n",
      " [[  2  49  63 209  29   3   7   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 14  11   2   9  55   3   7  63 122 276 163 457 306   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "x_train = pad_sequences(train_seq, maxlen=50, padding='post', truncating='post')\n",
    "print(train_seq[:2], '\\n\\n' ,x_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10003,)\n",
      "[['card_arrival']\n",
      " ['card_arrival']\n",
      " ['card_arrival']\n",
      " ...\n",
      " ['country_support']\n",
      " ['country_support']\n",
      " ['country_support']]\n",
      "[[12]\n",
      " [12]\n",
      " [12]\n",
      " ...\n",
      " [25]\n",
      " [25]\n",
      " [25]]\n"
     ]
    }
   ],
   "source": [
    "# 3. label to codes\n",
    "train_labels = pd.Categorical(df_train['category']).codes\n",
    "print(train_labels.shape)\n",
    "\n",
    "# 3.1 What does reshape does ?\n",
    "# -> The -1 is a placeholder that means “adjust this dimension to make the data fit”.\n",
    "# Asking numpy to reshape the array with 1 column and as many rows as possible\n",
    "print(df_train['category'].values.reshape(-1, 1))\n",
    "\n",
    "y_train = train_labels.reshape(-1, 1)\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
